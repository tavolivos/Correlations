{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('veda_intermareal/normalizado.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().to_csv(\"description.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "# normality test\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "data = df['M.O']\n",
    "\n",
    "plt.hist(data)\n",
    "\n",
    "stat, p = shapiro(data)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization by Simple Feature Scaling\n",
    "df[\"Biomasa_normal\"] = df[\"Biomasa\"]/df[\"Biomasa\"].max()\n",
    "#Normalization by Min-max\n",
    "df[\"Biomasa_normal\"] = (df[\"Biomasa\"]-df[\"Biomasa\"].min())/(df[\"Biomasa\"].max()-df[\"Biomasa\"].min())\n",
    "#Normalization by Z-score\n",
    "df[\"Biomasa_normal\"] = (df[\"Biomasa\"]-df[\"Biomasa\"].mean())/df[\"Biomasa\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization by log or raiz\n",
    "from math import sqrt\n",
    "\n",
    "df[\"Biomasa\"] = np.log(df['Biomasa'])\n",
    "df[\"Abundancia\"] = np.log(df['Abundancia'])\n",
    "df[\"Equidad de Pielou\"] = np.log(df['Equidad de Pielou'])\n",
    "\n",
    "\n",
    "df.to_csv(\"normalizado.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "sqrt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk Test\n",
    "# normality test\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "data = df['NE']\n",
    "\n",
    "plt.hist(data)\n",
    "\n",
    "stat, p = shapiro(data)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "rho = df.corr()\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t]))\n",
    "corelation = rho.round(2).astype(str) + p\n",
    "new = corelation.append(pval)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import scipy.stats  as stats\n",
    "\n",
    "\n",
    "rho = df.corr()\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t]))\n",
    "corelation = rho.round(2).astype(str) + p \n",
    "#concatenated = pd.concat([corelation, pval], join='inner', axis=1)\n",
    "#new = pd.concat([corelation, pval])\n",
    "#cor = corelation.merge(pval,left_index=True, right_index=True, how='left')\n",
    "df_columns = corelation.columns.values\n",
    "for i in range(0, len(corelation.index)):\n",
    "    for j in range(0, len(corelation.columns)):\n",
    "        print(corelation.values[i,j],pval.values[i,j],i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pearsonr(df.Biomasa, df.NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "rho = df.corr()\n",
    "pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t]))\n",
    "corelation = rho.round(2).astype(str) + p\n",
    "frames = [corelation, pval]\n",
    "corelation.to_csv(\"correlation.csv\")\n",
    "corelation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important correlations\n",
    "attrs = rho.iloc[:-1,:-1] # all except target\n",
    "# only important correlations and not auto-correlations\n",
    "threshold = 0.5\n",
    "# {('LSTAT', 'TAX'): 0.543993, ('INDUS', 'RAD'): 0.595129, ...\n",
    "important_corrs = (attrs[abs(attrs) > threshold][attrs != 1.0]).unstack().dropna().to_dict()\n",
    "#unique correlations\n",
    "unique_important_corrs = pd.DataFrame(list(set([(tuple(sorted(key)), important_corrs[key])\n",
    "    for key in important_corrs])), columns=['attribute pair', 'correlation'])\n",
    "# sorted by absolute value\n",
    "unique_important_corrs = unique_important_corrs.iloc[abs(unique_important_corrs['correlation']).argsort()[::-1]]\n",
    "unique_important_corrs.to_csv(\"importantcorrelation.csv\")\n",
    "print(unique_important_corrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def corrdot(*args, **kwargs):\n",
    "    corr_r = args[0].corr(args[1], 'pearson')\n",
    "    corr_text = f\"{corr_r:2.2f}\".replace(\"0.\", \".\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "    marker_size = abs(corr_r) * 10000\n",
    "    ax.scatter([.5], [.5], marker_size, [corr_r], alpha=0.6, cmap=\"coolwarm\",\n",
    "               vmin=-1, vmax=1, transform=ax.transAxes)\n",
    "    font_size = abs(corr_r) * 40 + 5\n",
    "    ax.annotate(corr_text, [.5, .5,],  xycoords=\"axes fraction\",\n",
    "                ha='center', va='center', fontsize=font_size)\n",
    "\n",
    "sns.set(style='white', font_scale=1.6)\n",
    "\n",
    "g = sns.PairGrid(df, aspect=1.4, diag_sharey=False)\n",
    "g.map_lower(sns.regplot, lowess=True, ci=False, line_kws={'color': 'black'})\n",
    "g.map_diag(sns.distplot, kde_kws={'color': 'black'})\n",
    "g.map_upper(corrdot)\n",
    "g.savefig(\"output.png\")\n",
    "\n",
    "#plt.savefig(\"figure.png\", format='png', dpi=350, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uthors <- data.frame(\n",
    "    surname = c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"McNeil\"),\n",
    "    nationality = c(\"US\", \"Australia\", \"US\", \"UK\", \"Australia\"),\n",
    "    retired = c(\"yes\", rep(\"no\", 4)))\n",
    "books <- data.frame(\n",
    "    name = c(\"Tukey\", \"Venables\", \"Tierney\", \"Ripley\", \"Ripley\", \"McNeil\"),\n",
    "    title = c(\"Exploratory Data Analysis\",\n",
    "              \"Modern Applied Statistics ...\",\n",
    "              \"LISP-STAT\",\n",
    "              \"Spatial Statistics\", \"Stochastic Simulation\",\n",
    "               \"Interactive Data Analysis\"),\n",
    "    other.author = c(NA, \"Ripley\", NA, NA, NA, NA))\n",
    "\n",
    "merge(authors, books, by.x=\"surname\", by.y=\"name\")\n",
    "merge(books, authors, by.x=\"name\", by.y=\"surname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
